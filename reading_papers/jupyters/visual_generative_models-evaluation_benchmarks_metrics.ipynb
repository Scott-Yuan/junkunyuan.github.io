{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "807b8515-0ea0-46f0-b8ce-6ca40a2dbf4a",
   "metadata": {},
   "source": [
    "# Visual Generation Evaluation Benchmarks and Metrics\n",
    "\n",
    "Introduction and implementations of visual generation evaluation benchmarks and metrics.\n",
    "\n",
    "Written by yuanjk0921@outlook.com\n",
    "\n",
    "See more reading papers and notes [here](https://junkunyuan.github.io/reading_papers/reading_papers.html)\n",
    "\n",
    "Updated on Feb 23, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbdc0c2-5aa1-4b6e-b446-04cc3c8a0b85",
   "metadata": {},
   "source": [
    "**Contents**\n",
    "<!-- - Inception Score -->\n",
    "<!-- - FID -->\n",
    "<!-- - FVD -->\n",
    "<!-- - CLIPScore -->\n",
    "<!-- - HPS / HPSv2 -->\n",
    "<!-- - ImageReward -->\n",
    "- T2I-CompBench\n",
    "<!-- - GenEval -->\n",
    "<!-- - VBench -->\n",
    "<!-- - T2V-CompBench -->\n",
    "<!-- - DPG-Bench -->\n",
    "<!-- - T2V-CompBench -->\n",
    "\n",
    "**References**\n",
    "- [**T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation** *(NeurIPS 2023)*](https://arxiv.org/pdf/2307.06350): The paper to introduce the T2I-CompBench."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb390bf-f621-4d4b-b2cb-b6b70e682640",
   "metadata": {},
   "source": [
    "## T2I-CompBench\n",
    "\n",
    "T2I-CompBench is designed for **image generation** on <u>compositional generation</u>, including attribute binding, object relationship, and complex compositions.\n",
    "\n",
    "### 1. Attribute Binding\n",
    "\n",
    "#### 1.1 Color\n",
    "\n",
    "**Data:** [All data (1000 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/color.txt) & [Training data (700 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/color_train.txt) & [Test data (300 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/color_val.txt)\n",
    "\n",
    "**Metrics:** use the VQA ability of BLIP for evaluating the probability of answering \"yes\".\n",
    "\n",
    "**Sources:** 480 prompts from CC500, 200 prompts from COCO, and 320 prompts generated by ChatGPT.\n",
    "\n",
    "**Examples:**\n",
    "- a green bench and a blue bowl\n",
    "- A bright yellow wall in a bathroom adds appeal to a white tiled floor.\n",
    "\n",
    "#### 1.2 Shape\n",
    "\n",
    "[All data (1000 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/shape.txt) & [Training data (700 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/shape_train.txt) & [Test data (300 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/shape_val.txt)\n",
    "\n",
    "**Metrics:** use the VQA ability of BLIP for evaluating the probability of answering \"yes\".</u>\n",
    "\n",
    "**Sources:** generated by ChatGPT by prompting with the shape set of {long, tall, short, big, small, cubic, ...}.\n",
    "\n",
    "**Examples:**\n",
    "- a pyramidal paperweight and a teardrop pen\n",
    "- The pyramidal roof and the triangular archway were the defining features of the ancient temple.\n",
    "\n",
    "#### 1.3 Texture\n",
    "\n",
    "[All data (1000 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/texture.txt) & [Training data (700 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/texture_train.txt) & [Test data (300 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/texture_val.txt)\n",
    "\n",
    "**Metrics:** use the VQA ability of BLIP for evaluating the probability of answering \"yes\".\n",
    "\n",
    "**Sources:** 800 prompts generated by random combinations of texture sets and 200 prompts are generated by ChatGPT.\n",
    "\n",
    "**Examples:**\n",
    "- a rubber eraser and a metallic key\n",
    "- The wooden hanger and metallic hook support the fluffy bathrobe in the bathroom.\n",
    "\n",
    "### 2. Object Relationship\n",
    "\n",
    "#### 2.1 Spatial relationships\n",
    "\n",
    "[All data (1000 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/spatial.txt) & [Training data (700 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/spatial_train.txt) & [Test data (300 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/spatial_val.txt)\n",
    "\n",
    "**Metrics:** use UniDet to detect objects and detetmine the spatial relationship by comparing the bounding boxes.\n",
    "\n",
    "**Sources:** random combinations of a spatial set of {on the side of, next to, on the right of, ...}\n",
    "\n",
    "**Examples:**\n",
    "- a book on the top of a woman\n",
    "- a turtle next to a airplane\n",
    "\n",
    "\n",
    "#### 2.2 Non-spatial relationships\n",
    "\n",
    "[All data (1000 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/non_spatial.txt) & [Training data (700 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/non_spatial_train.txt) & [Test data (300 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/non_spatial_val.txt)\n",
    "\n",
    "**Metrics:** CLIPScore.\n",
    "\n",
    "**Sources:** generated by ChatGPT.\n",
    "\n",
    "**Examples:**\n",
    "- A person is yawning in a boring meeting.\n",
    "- A runner is pushing themselves to go just a little bit farther, feeling their heart race and their muscles ache.\n",
    "\n",
    "## 3. Complex Compositions\n",
    "\n",
    "[All data (1000 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/complex.txt) & [Training data (700 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/complex_train.txt) & [Test data (300 prompts)](https://github.com/Karine-Huang/T2I-CompBench/blob/main/examples/dataset/complex_val.txt)\n",
    "\n",
    "**Metrics:** the average score of each dimension.\n",
    "\n",
    "**Sources:** generate 250 prompts with ChatGPT for each of the four scenarios: \"two objects with multiple attributes\", \"two objects with mixed attributes\", \"more than two objects with multiple attributes\", \"more than two objects with mixed attributes\".\n",
    "\n",
    "**Examples:**\n",
    "- The soft blanket draped over the bumpy couch and the hard floor.\n",
    "- The sleek, aerodynamic shape of the sports car cut through the wind with ease, a symbol of speed and luxury."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
